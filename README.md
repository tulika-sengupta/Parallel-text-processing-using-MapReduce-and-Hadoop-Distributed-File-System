# Parallel-text-processing-using-MapReduce-and-Hadoop-Distributed-File-System
- Designed Map Reduce Algorithm apply MapReduce (MR) algorithm for processing large data sets.
- Stored and retrieved text data in Hadoop Distributed File System (HDFS) as <key,value>.
- Collected tweets and used Map Reduce algorithm to perform Word Cooccurence with pairs and stripes method on the tweets collected.   
- Performed normalization and lemmatization on Classical Latin text files and implemented word 
  count on the same.  
- Scaled up the word co-occurrence by increasing the number of documents processed from 2 to n. 
   Recorded the performance of the MR infrastructure.
- From word co-occurrence that deals with just 2-grams (or two words co-occurring) increased
  the co-occurrence to n=3 or 3 words co-occurring.
